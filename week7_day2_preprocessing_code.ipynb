{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **‚ÄúThis notebook compares CountVectorizer vs. TF-IDF features for spam detection using Multinomial Naive Bayes.‚Äù**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SL-dw1q-ufzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚ÄúSpam classification using countvectorizer features and Naive Bayes.**\n",
        "\n",
        "Step 1 ‚Äì Load and inspect data\n",
        "upload code for reading the sms.tsv file and basic checks.\n",
        "\n",
        "Step 2 ‚Äì Pre-processing\n",
        "\n",
        "Lowercase\n",
        "\n",
        "Remove punctuation\n",
        "\n",
        "Label-encode\n",
        "\n",
        "Step 3 ‚Äì Train/Test split\n",
        "Same as before.\n",
        "\n",
        "Step 4 ‚Äì Count Vectorization + Model Training\n",
        "\n",
        "Step 5 ‚Äì Results & Comparison\n"
      ],
      "metadata": {
        "id": "5QViWyRZUwaM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iX4c_H2Ohsi3"
      },
      "outputs": [],
      "source": [
        "#loading data\n",
        "import pandas as pd\n",
        "url=\"http://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df=pd.read_csv(url, sep='\\t',header=None, names=['label','messages'])\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n",
        "df['label'].value_counts()\n",
        "df.isna().sum()\n",
        "#Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "df['label_num']=le.fit_transform(df['label'])\n",
        "df[['label','label_num']]\n",
        "# lowercase messages (recommended for text modeling like counter vectorization)\n",
        "df['messages']=df['messages'].str.lower().str.replace(r'[^\\w\\s]',' ',regex=True)\n",
        "#Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "#features and target\n",
        "x=df['messages']\n",
        "y=df['label_num']\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
        "len(x_train),len(y_train),len(x_test),len(y_test)\n",
        "\n",
        "#CounterVectorization\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(stop_words='english',ngram_range=(1,2))\n",
        "x_train_cv = cv.fit_transform(x_train)\n",
        "x_test_cv  = cv.transform(x_test)\n",
        "\n",
        "print(x_train_cv.shape, x_test_cv.shape)\n",
        "#Train a classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "model=MultinomialNB()\n",
        "model.fit(x_train_cv,y_train)\n",
        "#predictions\n",
        "y_pred=model.predict(x_test_cv)\n",
        "#evaluation\n",
        "print(\"Accuracy :\" , accuracy_score(y_test,y_pred))\n",
        "print(\"\\nClassification Report \\n \",classification_report(y_test,y_pred))\n",
        "print(\"\\nConfusion Matrix \\n\",confusion_matrix(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üü¢ Bottom Line\n",
        "\n",
        "* The detector is **very accurate**.\n",
        "* Only a handful of normal messages were falsely flagged (FP).\n",
        "* It caught almost all spam, missing only a small number (FN).\n"
      ],
      "metadata": {
        "id": "3QTgRJ8ZNhxc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **‚ÄúSpam classification using TF-IDF features and Naive Bayes. Goal: compare with previous CountVectorizer model.‚Äù**\n",
        "\n",
        "Step 1 ‚Äì Load and inspect data\n",
        "Reuse my earlier code for reading the sms.tsv file and basic checks.\n",
        "\n",
        "Step 2 ‚Äì Pre-processing\n",
        "\n",
        "Lowercase\n",
        "\n",
        "Remove punctuation\n",
        "\n",
        "Label-encode\n",
        "\n",
        "Step 3 ‚Äì Train/Test split\n",
        "Same as before.\n",
        "\n",
        "Step 4 ‚Äì TF-IDF Vectorization + Model Training\n",
        "\n",
        "\n",
        "Step 5 ‚Äì Results & Comparison\n"
      ],
      "metadata": {
        "id": "cuWexb1iUq06"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzTxwp_uVe4n"
      },
      "outputs": [],
      "source": [
        "#loading data\n",
        "import pandas as pd\n",
        "url=\"http://raw.githubusercontent.com/justmarkham/pycon-2016-tutorial/master/data/sms.tsv\"\n",
        "df=pd.read_csv(url, sep='\\t',header=None, names=['label','messages'])\n",
        "df.head()\n",
        "df.info()\n",
        "df.describe()\n",
        "df['label'].value_counts()\n",
        "df.isna().sum()\n",
        "#Label encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "df['label_num']=le.fit_transform(df['label'])\n",
        "df[['label','label_num']]\n",
        "# lowercase messages (recommended for text modeling like counter vectorization)\n",
        "df['messages']=df['messages'].str.lower().str.replace(r'[^\\w\\s]',' ',regex=True)\n",
        "#Train/Test Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "#features and target\n",
        "x=df['messages']\n",
        "y=df['label_num']\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42,stratify=y)\n",
        "len(x_train),len(y_train),len(x_test),len(y_test)\n",
        "#CounterVectorization\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        " #TF-IDF features\n",
        "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,2))\n",
        "x_train_tfidf = tfidf.fit_transform(x_train)\n",
        "x_test_tfidf  = tfidf.transform(x_test)\n",
        "\n",
        "#Train a classifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix\n",
        "model=MultinomialNB()\n",
        "model.fit(x_train_tfidf,y_train)\n",
        "#predictions\n",
        "y_pred=model.predict(x_test_tfidf)\n",
        "#evaluation\n",
        "print(\"Accuracy :\" , accuracy_score(y_test,y_pred))\n",
        "print(\"\\nClassification Report \\n \",classification_report(y_test,y_pred))\n",
        "print(\"\\nConfusion Matrix \\n\",confusion_matrix(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***üü¢ Bottom Line ‚Äì TF-IDF Model***\n",
        "\n",
        "The TF-IDF version is similarly high-performing, with accuracy on par (or slightly higher) than CountVectorizer.\n",
        "\n",
        "Because TF-IDF down-weights very common words, it focuses more on distinctive terms, leading to even fewer false positives in many runs.\n",
        "\n",
        "Spam detection remains strong‚Äîalmost every spam message is caught, with only a small number of false negatives."
      ],
      "metadata": {
        "id": "j0Bz0kztvm5F"
      }
    }
  ]
}